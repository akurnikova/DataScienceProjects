{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from keras.layers import Input, Dense,MaxPooling2D,Flatten, Conv2D,BatchNormalization,Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51940\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Train/'\n",
    "dev_data_dir = '/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Dev/'\n",
    "test_data_dir = '/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Test/'\n",
    "\n",
    "# dimensions of the images.\n",
    "#img_width, img_height = 240, 150\n",
    "\n",
    "N_train_samples = 47922\n",
    "N_dev_samples = 4018\n",
    "N_test_samples = 10798\n",
    "\n",
    "print(N_train_samples+N_dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train images from directory\n",
    "if 0:\n",
    "    train_array = []\n",
    "    i_file = 0\n",
    "    for f in range(N_train_samples):\n",
    "        file = train_data_dir+'Im'+str(i_file)+'.png'\n",
    "        train_array.append(cv2.imread(file))\n",
    "        i_file+=1\n",
    "    train_array = np.asarray(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dev images from directory\n",
    "dev_array = []\n",
    "i_file = 0\n",
    "for f in range(N_dev_samples):\n",
    "    file = dev_data_dir+'Im'+str(i_file)+'.png'\n",
    "    dev_array.append(cv2.imread(file))\n",
    "    i_file+=1\n",
    "dev_array = np.asarray(dev_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load test images from directory\n",
    "if 1:\n",
    "    test_array = []\n",
    "    i_file = 0\n",
    "    for f in range(N_test_samples):\n",
    "        file = test_data_dir+'Im'+str(i_file)+'.png'\n",
    "        test_array.append(cv2.imread(file))\n",
    "        i_file+=1\n",
    "    test_array = np.asarray(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse labels file\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Labels_train.txt', 'r') \n",
    "labels_train = file.read().split()\n",
    "file.close()\n",
    "labels_train = np.asarray(labels_train).astype('float32')\n",
    "\n",
    "## Parse labels file\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Labels_dev.txt', 'r') \n",
    "labels_dev = file.read().split()\n",
    "file.close()\n",
    "labels_dev = np.asarray(labels_dev).astype('float32')\n",
    "\n",
    "\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/T_train.txt', 'r') \n",
    "T_train = file.read().split()\n",
    "file.close()\n",
    "T_train = np.asarray(T_train).astype('float32')\n",
    "\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/T_dev.txt', 'r') \n",
    "T_dev = file.read().split()\n",
    "file.close()\n",
    "T_dev = np.asarray(T_dev).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "   # X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X_input)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "  #  # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv1')(X_input)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    ## NOTE: Option to ass a FC layer here but\n",
    "    ## Model on the flow, angles and acc did better on a short training with no fully connected layer\n",
    "    #X = Dense(5, name='d64')(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    #sX = Dropout(0.5)(X)\n",
    "\n",
    "    ## Output layer\n",
    "    X = Dense(1, name='fc')(X)\n",
    "    \n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='SpeedModel')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "spModel = model(np.asarray(dev_array[0]).shape)\n",
    "spModel.load_weights('Boost_model_full'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 150, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 148, 238, 32)      896       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 148, 238, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 148, 238, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 74, 119, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 281792)            0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 281793    \n",
      "=================================================================\n",
      "Total params: 282,817\n",
      "Trainable params: 282,753\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "spModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_speed_T = []\n",
    "for i in [0]: #np.arange(2,10,1):\n",
    "  #  if i == 0: continue\n",
    "    spModel = model(np.asarray(train_array[0]).shape)\n",
    "    spModel.load_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    \n",
    "    pred_speed_t = spModel.predict(x = train_array[:,:,:,:])\n",
    "    \n",
    "    with open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/predictions/train' + str(i) + '.txt', 'w') as f:\n",
    "        for item in pred_speed_t:\n",
    "            f.write(\"%s\\n\" % item[0])\n",
    "    \n",
    "#    pred_speed_T.append(pred_speed_t)\n",
    "    \n",
    "#pred_speed_T = np.asarray(pred_speed_T)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 time: 430.1\n",
      "Iter 1 time: 436.6\n",
      "Iter 2 time: 459.1\n",
      "Iter 3 time: 461.8\n",
      "Iter 4 time: 466.2\n",
      "Iter 5 time: 435.4\n",
      "Iter 6 time: 465.1\n",
      "Iter 7 time: 3996.2\n",
      "Iter 8 time: 426.0\n",
      "Iter 9 time: 426.2\n",
      "Iter 10 time: 427.6\n",
      "Iter 11 time: 427.4\n",
      "Iter 12 time: 426.1\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,13,1):\n",
    "    tic = time.time()\n",
    "    spModel = model(np.asarray(test_array[0]).shape)\n",
    "    spModel.load_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    pred_speed_d = spModel.predict(x= test_array)\n",
    "\n",
    "    with open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/predictions/test' + str(i) + '.txt', 'w') as f:\n",
    "        for item in pred_speed_d:\n",
    "            f.write(\"%s\\n\" % item[0])\n",
    "    t = time.time()-tic\n",
    "    print('Iter %d time: %.1f'%(i,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_speed_D = []\n",
    "for i in np.arange(0,10,1):\n",
    "    spModel = model(np.asarray(dev_array[0]).shape)\n",
    "    spModel.load_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    \n",
    "    \n",
    "    pred_speed_d = spModel.predict(x = dev_array)\n",
    "\n",
    "    with open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/predictions/dev' + str(i) + '.txt', 'w') as f:\n",
    "        for item in pred_speed_d:\n",
    "            f.write(\"%s\\n\" % item[0])\n",
    "    \n",
    "    pred_speed_D.append(pred_speed_d)\n",
    "    \n",
    "pred_speed_D = np.asarray(pred_speed_D)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array_boost_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_boost_D = np.mean(pred_speed_D,axis = 0)\n",
    "array_boost_T = np.mean(pred_speed_T,axis = 0)\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from scipy.signal import medfilt\n",
    "                     \n",
    "for i in range(len(pred_speed_T)):\n",
    "    mse_train = np.mean((pred_speed_T[i,:]-labels_train)**2)\n",
    "    #mse_dev = np.mean((pred_speed_D[i,:]-labels_dev)**2)\n",
    "    mse_dev = 0\n",
    "    print('Train %.2f, Test %.2f'%(mse_train,mse_dev))\n",
    "    \n",
    "print(np.mean((array_boost_T-labels_train)**2))\n",
    "\n",
    "print(np.mean((array_boost_D-labels_dev)**2))\n",
    "\n",
    "#data = np.hstack((T_train, array_boost_T))\n",
    "#model = SimpleExpSmoothing(data)\n",
    "#model_fit = model.fit()\n",
    "#yhat = model_fit.predict(T_train)\n",
    "yhat = medfilt(array_boost_D,25)\n",
    "print(np.mean((labels_dev-yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(T_train,array_boost_T,'b.')\n",
    "plt.plot(T_train,yhat,'m.')\n",
    "plt.plot(T_train,labels_train,'r.')\n",
    "\n",
    "plt.plot(T_dev,array_boost_D,'g.')\n",
    "plt.plot(T_dev,labels_dev,'r.')\n",
    "plt.plot(T_dev,yhat,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
