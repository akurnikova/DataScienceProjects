{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from keras.layers import Input, Dense,MaxPooling2D,Flatten, Conv2D,BatchNormalization,Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51940\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Train/'\n",
    "dev_data_dir = '/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Dev/'\n",
    "test_data_dir = '/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Test/'\n",
    "\n",
    "# dimensions of the images.\n",
    "#img_width, img_height = 240, 150\n",
    "\n",
    "N_train_samples = 47922\n",
    "N_dev_samples = 4018\n",
    "N_test_samples = 10798\n",
    "\n",
    "print(N_train_samples+N_dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load train images from directory\n",
    "train_array = []\n",
    "i_file = 0\n",
    "for f in range(N_train_samples):\n",
    "    file = train_data_dir+'Im'+str(i_file)+'.png'\n",
    "    train_array.append(cv2.imread(file))\n",
    "    i_file+=1\n",
    "train_array = np.asarray(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dev images from directory\n",
    "dev_array = []\n",
    "i_file = 0\n",
    "for f in range(N_dev_samples):\n",
    "    file = dev_data_dir+'Im'+str(i_file)+'.png'\n",
    "    dev_array.append(cv2.imread(file))\n",
    "    i_file+=1\n",
    "dev_array = np.asarray(dev_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load test images from directory\n",
    "test_array = []\n",
    "i_file = 0\n",
    "for f in range(N_test_samples):\n",
    "    file = test_data_dir+'Im'+str(i_file)+'.png'\n",
    "    test_array.append(cv2.imread(file))\n",
    "    i_file+=1\n",
    "test_array = np.asarray(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse labels file\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Labels_train.txt', 'r') \n",
    "labels_train = file.read().split()\n",
    "file.close()\n",
    "labels_train = np.asarray(labels_train).astype('float32')\n",
    "\n",
    "## Parse labels file\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/Labels_dev.txt', 'r') \n",
    "labels_dev = file.read().split()\n",
    "file.close()\n",
    "labels_dev = np.asarray(labels_dev).astype('float32')\n",
    "\n",
    "\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/T_train.txt', 'r') \n",
    "T_train = file.read().split()\n",
    "file.close()\n",
    "T_train = np.asarray(T_train).astype('float32')\n",
    "\n",
    "file = open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/T_dev.txt', 'r') \n",
    "T_dev = file.read().split()\n",
    "file.close()\n",
    "T_dev = np.asarray(T_dev).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "   # X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X_input)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "  #  # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv1')(X_input)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    ## NOTE: Option to ass a FC layer here but\n",
    "    ## Model on the flow, angles and acc did better on a short training with no fully connected layer\n",
    "    #X = Dense(5, name='d64')(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    #sX = Dropout(0.5)(X)\n",
    "\n",
    "    ## Output layer\n",
    "    X = Dense(1, name='fc')(X)\n",
    "    \n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='SpeedModel')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47922,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f842e9364d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#spModel = model(np.asarray(train_array[:,:,:,:][0]).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_array' is not defined"
     ]
    }
   ],
   "source": [
    "print(labels_train.shape)\n",
    "print(np.asarray(train_array).shape)\n",
    "#spModel = model(np.asarray(train_array[:,:,:,:][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spModel.compile(optimizer = 'adam', loss = \"mean_squared_error\", metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history2step = spModel.fit(x = train_array[:,:,:,:], y = labels_train, epochs = 2, batch_size = 16)\n",
    "#spModel.save_weights('N2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = spModel.evaluate(x = dev_array[:,:,:,:], y = labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_speed_t = spModel.predict(x = train_array[:,:,:,:])\n",
    "#pred_speed_d = spModel.predict(x = dev_array[:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10,7))\n",
    "#plt.plot(T_train,pred_speed_t,'b.')\n",
    "#plt.plot(T_train,labels_train,'r.')\n",
    "\n",
    "#plt.plot(T_dev,pred_speed_d,'g.')\n",
    "#plt.plot(T_dev,labels_dev,'m.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES ON MODELS\n",
    "\n",
    "**3 input (angle,mag,acc), 2 conv layers:** \n",
    "mse 6.0719 after 2 epochs, 9.8 on dev set, predicted values are higher than expected maybe would do better with smoothing or a time dependence\n",
    "\n",
    "\n",
    "**3 input (angle,mag,acc), 2 conv layers PLUS Dense64 layer:** Stopped - mse stays too high during training\n",
    "\n",
    "**3 input (angle,mag,acc), 2 conv layers PLUS Dense5 layer:**\n",
    "mse  after 2 epochs,  on dev set, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting creative: Try boosting the NN, by running 10 x and averaging the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "47922/47922 [==============================] - 5602s 117ms/step - loss: 97.3728 - mean_squared_error: 97.3728\n",
      "Epoch 2/2\n",
      "47922/47922 [==============================] - 8143s 170ms/step - loss: 20.7748 - mean_squared_error: 20.7748\n",
      "Fit time: 13745.69\n",
      "Epoch 1/2\n",
      "47922/47922 [==============================] - 8032s 168ms/step - loss: 91.3669 - mean_squared_error: 91.3669\n",
      "Epoch 2/2\n",
      "47922/47922 [==============================] - 15299s 319ms/step - loss: 16.3041 - mean_squared_error: 16.3041\n",
      "Fit time: 23332.70\n",
      "Epoch 1/2\n",
      "20448/47922 [===========>..................] - ETA: 41:04 - loss: 151.8375 - mean_squared_error: 151.8375"
     ]
    }
   ],
   "source": [
    "pred_speed_T = []\n",
    "pred_speed_D = []\n",
    "tic = time.time()\n",
    "for i in np.arange(10,15,1):\n",
    " #   idx = (np.random.random(10000)*N_train_samples).astype(int)\n",
    "    spModel = model(np.asarray(train_array[0]).shape)\n",
    "    spModel.compile(optimizer = 'adam', loss = \"mean_squared_error\", metrics = ['mse'])\n",
    "    spModel.fit(x = train_array, y = labels_train, epochs = 2, batch_size = 16)\n",
    "    spModel.save_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    \n",
    "    print('Fit time: %.2f'%(time.time()-tic))\n",
    "    tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_speed_T = []\n",
    "for i in [0]: #np.arange(2,10,1):\n",
    "  #  if i == 0: continue\n",
    "    spModel = model(np.asarray(train_array[0]).shape)\n",
    "    spModel.load_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    \n",
    "    pred_speed_t = spModel.predict(x = train_array[:,:,:,:])\n",
    "    \n",
    "    with open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/predictions/train' + str(i) + '.txt', 'w') as f:\n",
    "        for item in pred_speed_t:\n",
    "            f.write(\"%s\\n\" % item[0])\n",
    "    \n",
    "#    pred_speed_T.append(pred_speed_t)\n",
    "    \n",
    "#pred_speed_T = np.asarray(pred_speed_T)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0,10,1):\n",
    "    spModel = model(np.asarray(test_array[0]).shape)\n",
    "    spModel.load_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    pred_speed_d = spModel.predict(x = test_array[:,:,:,:])\n",
    "\n",
    "    with open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/predictions/test' + str(i) + '.txt', 'w') as f:\n",
    "        for item in pred_speed_d:\n",
    "            f.write(\"%s\\n\" % item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_speed_D = []\n",
    "for i in np.arange(0,10,1):\n",
    "    spModel = model(np.asarray(dev_array[0]).shape)\n",
    "    spModel.load_weights('Boost_model_full'+str(i)+'.h5')\n",
    "    \n",
    "    pred_speed_d = spModel.predict(x = dev_array[:,:,:,:])\n",
    "\n",
    "    with open('/home/asya/Documents/CodePractice/SpeedChallenge/speed_challenge_2017/data/predictions/dev' + str(i) + '.txt', 'w') as f:\n",
    "        for item in pred_speed_d:\n",
    "            f.write(\"%s\\n\" % item[0])\n",
    "    \n",
    "    pred_speed_D.append(pred_speed_d)\n",
    "    \n",
    "pred_speed_D = np.asarray(pred_speed_D)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array_boost_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_boost_D = np.mean(pred_speed_D,axis = 0)\n",
    "array_boost_T = np.mean(pred_speed_T,axis = 0)\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from scipy.signal import medfilt\n",
    "                     \n",
    "for i in range(len(pred_speed_T)):\n",
    "    mse_train = np.mean((pred_speed_T[i,:]-labels_train)**2)\n",
    "    #mse_dev = np.mean((pred_speed_D[i,:]-labels_dev)**2)\n",
    "    mse_dev = 0\n",
    "    print('Train %.2f, Test %.2f'%(mse_train,mse_dev))\n",
    "    \n",
    "print(np.mean((array_boost_T-labels_train)**2))\n",
    "\n",
    "print(np.mean((array_boost_D-labels_dev)**2))\n",
    "\n",
    "#data = np.hstack((T_train, array_boost_T))\n",
    "#model = SimpleExpSmoothing(data)\n",
    "#model_fit = model.fit()\n",
    "#yhat = model_fit.predict(T_train)\n",
    "yhat = medfilt(array_boost_D,25)\n",
    "print(np.mean((labels_dev-yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(T_train,array_boost_T,'b.')\n",
    "plt.plot(T_train,yhat,'m.')\n",
    "plt.plot(T_train,labels_train,'r.')\n",
    "\n",
    "plt.plot(T_dev,array_boost_D,'g.')\n",
    "plt.plot(T_dev,labels_dev,'r.')\n",
    "plt.plot(T_dev,yhat,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
